{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Leonhart8902/Scratch_Detection_Thesis/blob/main/Skripsi_19_1_2023.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Library Import<h1/>\n",
        "<p>\n",
        "<b> Import all library that will be used for the program later in one cell. The editing of the library all will be done in the cell below.<b/>\n",
        "<p/>"
      ],
      "metadata": {
        "id": "hr103vrKqA-c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "4eM7SM5qtEGU",
        "outputId": "3234d674-1f7d-40bc-a620-485fe09a2b45",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import copy\n",
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "gfEzZIHLp5Dw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Data_aug(org_dir,aug_dir,aug_num):\n",
        "  '''\n",
        "  org_dir = Refer to the original directory for the images\n",
        "  aug_dir = Refer to the directory where the augmented images will be saved later\n",
        "  aug_num = number of augmented image produces per original images\n",
        "  '''\n",
        "  datagen = ImageDataGenerator(\n",
        "      rotation_range=30,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "  # specify the directory where the original images are located\n",
        "  directory = org_dir\n",
        "\n",
        "  # loop through the directory and apply data augmentation to each image\n",
        "  for root, dirs, files in os.walk(directory):\n",
        "      for file in files:\n",
        "          if file.endswith(\".jpg\"):\n",
        "              img = cv2.imread(os.path.join(root, file))\n",
        "              x = img.reshape((1,) + img.shape)\n",
        "              i = 0\n",
        "              for batch in datagen.flow(x, batch_size=1, save_to_dir = aug_dir, save_prefix='', save_format='jpg'):\n",
        "                  i += 1\n",
        "                  if i > aug_num: # number of augmented images to generate per original image\n",
        "                      break\n"
      ],
      "metadata": {
        "id": "y6-Szql8q_F3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2> Creating Dataset <h2/>\n",
        "<p>\n",
        "<b>The codes below are used to create the dataset from the NG and G images that has been taken before<b/>\n",
        "<p/>"
      ],
      "metadata": {
        "id": "oCGbzljcsrKc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "galez1UHVbTz"
      },
      "outputs": [],
      "source": [
        "def Create_dataset(Directory):\n",
        "  # set the directory path where the NG and G folders are located\n",
        "  directory = Directory\n",
        "\n",
        "  # create an empty list to store the image data\n",
        "  image_data = []\n",
        "\n",
        "  # loop through the NG and Good folders and read in the images\n",
        "  for folder in ['NG', 'Good']:\n",
        "      for filename in os.listdir(os.path.join(directory, folder)):\n",
        "          if filename.endswith('.jpg'):\n",
        "              # read in the image\n",
        "              img = cv2.imread(os.path.join(directory, folder, filename))\n",
        "              # append the image data and the corresponding label to the list\n",
        "              image_data.append((img, folder))\n",
        "  return image_data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2> Make the Copy of Your Dataset for the Comparison <h2/>\n",
        "<p> \n",
        "<b>This copy is important so if you make any change in your dataset it won't destruct the original dataset that maybe you will need it in the future<b/>\n",
        "<p/>"
      ],
      "metadata": {
        "id": "VMRj7su4BIaI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def copy_dataset(Data_copied):\n",
        "  # make a copy of the original dataset\n",
        "  original_data = copy.deepcopy(Data_copied)\n",
        "  return original_data"
      ],
      "metadata": {
        "id": "u0MnwkMLBHmX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2> Resizing Your Dataset </h2>\n",
        "<p>\n",
        "<b>It's important for you to resizing your dataset so it could give a faster performance for your training later<b/>\n",
        "</p>"
      ],
      "metadata": {
        "id": "SJx-zzRnBjRD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Data_resize(Dataset):\n",
        "  # set the desired image size\n",
        "  new_size = (200,200)\n",
        "\n",
        "  # loop through the image data and resize each image\n",
        "  for i, data in enumerate(Dataset): #Enumerate used so the dataset won't change\n",
        "      img, label = data\n",
        "      # resize the image using numpy array\n",
        "      img = np.array(img)\n",
        "      img = cv2.resize(img, new_size)\n",
        "      Dataset[i] = (img, label)\n",
        "  return Dataset"
      ],
      "metadata": {
        "id": "M7z1lfEzByvf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1> Data Split <h1> \n",
        "<p>\n",
        "<b> The data needs to be split into training data and testing data. The separated data will be treated differently. <b>\n",
        "<p>"
      ],
      "metadata": {
        "id": "ANg2t54nKW6S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Split_data(Dataset):\n",
        "  # split the data into training and testing sets\n",
        "  train_data, test_data = train_test_split(Dataset, test_size=0.2)\n",
        "  return train_data, test_data"
      ],
      "metadata": {
        "id": "Qcl6wPziKPFz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1> Gabor Filtering <h1>\n",
        "<p> <b> To improve the texture of the image trained or tested, filtering is needed. In this case the usage of Gabor Filtering who can create a high spacial data is used to improved the surface texture of the images. <b> <p>"
      ],
      "metadata": {
        "id": "fhoNR7_eEcVo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Gabor_filtering(img):\n",
        "  kernel = cv2.getGaborKernel((24, 24), 2.0, 0, 10.0, 0.5, 0, ktype=cv2.CV_32F)\n",
        "  images = cv2.imread(img)\n",
        "  filtered_img = cv2.filter2D(images, cv2.CV_8UC3, kernel)"
      ],
      "metadata": {
        "id": "J3o7NsR-qSMW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2> Data Showing <h2/>\n",
        "<p>\n",
        "<b>The dataset that has been made before shown by using matplotlib. This data presentation is needed to check the quality of resized dataset.<b/>\n",
        "<p>"
      ],
      "metadata": {
        "id": "i4YVZECcSSqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Data_show(Dataset):\n",
        "  for i, data in enumerate(Dataset):\n",
        "    # get the first image and label from the dataset\n",
        "    img, label = data\n",
        "    # display the image using matplotlib\n",
        "    plt.imshow(img)\n",
        "    plt.title(label)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "tc2H7RttAiOv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1> Convert Labels <h1/>\n",
        "<p>\n",
        "<b> To train the data in the model with numerical approach, we need to convert the label in the data from 'NG' and 'Good' into the numerical value. <b>\n",
        "<p>\n",
        "<P>\n",
        "<B> This kind of conversion were done by using the LabelEncoder from ScikitLearn. The LabelEncoder will turn the desired label to a number instead of text. <b>\n",
        "<p>\n",
        "<p>\n",
        "<b> The label encoded then will be turned into OneHotEncoding for a better performance with multi-levels class like this program did. To turn it into OneHotEncoding, it needs to_categorical<b/>\n",
        "<p>"
      ],
      "metadata": {
        "id": "c-4Xv0RolrGw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Labeling (Dataset): \n",
        "  # convert the labels to numerical values\n",
        "  encoder = LabelEncoder()\n",
        "  y = [i[1] for i in Dataset]\n",
        "  encoder.fit(y)\n",
        "  y = encoder.transform(y)\n",
        "  #convert the label encoder to oneHotEncoding using to_categorical\n",
        "  y = to_categorical(y)"
      ],
      "metadata": {
        "id": "xUrnrNgnjS76"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1> Code test Running <h1>"
      ],
      "metadata": {
        "id": "ap4Ih6ORHbTp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = Create_dataset(\"/content/drive/MyDrive/Dataset\")\n",
        "original_dataset = copy_dataset(dataset)"
      ],
      "metadata": {
        "id": "CNSYAAfUHahs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resized_data = Data_resize(dataset)\n",
        "train_data, test_data = Split_data(resized_data)"
      ],
      "metadata": {
        "id": "LvpjNFr6Omxi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1N3ywq_SwQBW",
        "outputId": "6ba9d27d-e7c3-41df-eeba-d0d5262c08d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    }
  ]
}